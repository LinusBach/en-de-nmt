{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.mps\n",
    "\n",
    "from decoder import AttnDecoderRNN\n",
    "from encoder import EncoderRNN\n",
    "from evaluate import evaluate_losses, inference, evaluate_bleu, evaluate_loss\n",
    "from dataloader import Lang\n",
    "from io import open\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T04:55:40.291977Z",
     "start_time": "2023-06-16T04:55:40.262451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation size: 2534\n"
     ]
    }
   ],
   "source": [
    "initial_validation_size = 20000\n",
    "max_length = 20\n",
    "input_lang = Lang(\"en\")\n",
    "output_lang = Lang(\"de\")\n",
    "\n",
    "validation_english = open(\"data/train.en\", encoding='utf-8').readlines()[:initial_validation_size]\n",
    "validation_german = open(\"data/train.de\", encoding='utf-8').readlines()[:initial_validation_size]\n",
    "zipped = list(zip(validation_english, validation_german))\n",
    "validation_english = [english for english, german in zipped\n",
    "                      if len(input_lang.tokenize_without_truncation(english)) < max_length\n",
    "                      and len(output_lang.tokenize_without_truncation(german)) < max_length]\n",
    "validation_german = [german for english, german in zipped\n",
    "                     if len(input_lang.tokenize_without_truncation(english)) < max_length\n",
    "                     and len(output_lang.tokenize_without_truncation(german)) < max_length]\n",
    "# validation_german = [[output_lang.decode(token) for token in output_lang.tokenize(sentence)][1:-1] for sentence in validation_german]\n",
    "print(f\"validation size: {len(validation_english)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T04:55:46.831247Z",
     "start_time": "2023-06-16T04:55:40.266477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_list = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "model_names = [\n",
    "\"1e-3_lr_256_hidden_4_layers_20p_dropout\",\n",
    "\"1e-4_lr_320_hidden_4_layers_10p_dropout\",\n",
    "\"3e-4_lr_320_hidden_4_layers_20p_dropout\",\n",
    "\"3e-5_lr_320_hidden_5_layers_30p_dropout\",\n",
    "\"50p_tfr_1e-4_lr_320_hidden_4_layers_10p_dropout\",\n",
    "\"80p_tfr_3e-4_lr_320_hidden_5_layers_30p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_320_hidden_6_layers_40p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_512_hidden_8_layers_50p_dropout\",\n",
    "\"100p_tfr_2e-4_lr_400_hidden_8_layers_60p_dropout\",\n",
    "\"100p_tfr_5e-5_lr_512_hidden_8_layers_60p_dropout_1e-4_weight_decay\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T04:55:46.833978Z",
     "start_time": "2023-06-16T04:55:46.832127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "lstm_model_names = [\n",
    "\"50p_tfr_1e-4_lr_320_hidden_4_layers_10p_dropout\",\n",
    "\"80p_tfr_3e-4_lr_320_hidden_5_layers_30p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_320_hidden_6_layers_40p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_512_hidden_8_layers_50p_dropout\",\n",
    "\"100p_tfr_2e-4_lr_400_hidden_8_layers_60p_dropout\",\n",
    "\"100p_tfr_5e-5_lr_512_hidden_8_layers_60p_dropout_1e-4_weight_decay\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T04:55:46.847998Z",
     "start_time": "2023-06-16T04:55:46.834693Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 100p_tfr_1e-4_lr_320_hidden_6_layers_40p_dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2534/2534 [01:36<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.4230409764641365\n",
      "Evaluating model 100p_tfr_1e-4_lr_512_hidden_8_layers_50p_dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 1154/2534 [02:08<02:44,  8.39it/s]"
     ]
    }
   ],
   "source": [
    "# losses_list = []\n",
    "for i in range(6, 10):\n",
    "    models_dir = \"models_gru\"\n",
    "    model_name = model_names[i]\n",
    "    plots_dir = \"plots\"\n",
    "\n",
    "    encoder = torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device)\n",
    "    attn_decoder = torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device)\n",
    "    # prev_loss_history = np.load(os.path.join(plots_dir, model_name + \"_full_history.npy\")).tolist()\n",
    "    # prev_plot_history = np.load(os.path.join(plots_dir, model_name + \"_plot_history.npy\")).tolist()\n",
    "\n",
    "    print(f\"Evaluating model {model_name}\")\n",
    "    loss, losses = evaluate_losses(encoder, attn_decoder, validation_english, validation_german, input_lang, output_lang, max_length, device)\n",
    "    losses_list.append((loss, losses))\n",
    "    print(f\"Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-16T05:15:52.461499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T05:15:16.060436Z",
     "start_time": "2023-06-16T05:15:16.054582Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chencherry = SmoothingFunction()\n",
    "all_bleu_scores = []\n",
    "\n",
    "for i in range(6):\n",
    "    models_dir = \"models_lstm\"\n",
    "    model_name = lstm_model_names[i]\n",
    "    plots_dir = \"plots\"\n",
    "\n",
    "    encoder = torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device)\n",
    "    decoder = torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device)\n",
    "    # prev_loss_history = np.load(os.path.join(plots_dir, model_name + \"_full_history.npy\")).tolist()\n",
    "    # prev_plot_history = np.load(os.path.join(plots_dir, model_name + \"_plot_history.npy\")).tolist()\n",
    "\n",
    "    print(f\"Evaluating model {model_name}\")\n",
    "    bleu_scores = []\n",
    "    for j in tqdm(range(len(validation_english))):\n",
    "        prediction, _ = inference(encoder, decoder, validation_english[j], input_lang, output_lang, max_length, device)\n",
    "        bleu_score = sentence_bleu(validation_german[j], prediction[1:-1], (0.25, 0.25, 0.25, 0.25), smoothing_function=chencherry.method1)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    # print(f\"Prediction: {prediction[1:-1]}\")\n",
    "    print(f\"BLEU score: {np.mean(bleu_scores)}\")\n",
    "    all_bleu_scores.append(bleu_scores)\n",
    "    # loss, losses = evaluate_losses(encoder, attn_decoder, validation_english, validation_german, input_lang, output_lang, max_length, device)\n",
    "    # losses_list.append((loss, losses))\n",
    "    # print(f\"Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T04:56:02.794547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_of_interest = np.arange(len(lstm_model_names))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T04:56:02.796604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(losses_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T04:56:02.809505Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.boxplot([losses_list[i][1] for i in models_of_interest])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"plots/losses_boxplot.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T04:56:02.809714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.boxplot([all_bleu_scores[i] for i in models_of_interest])\n",
    "plt.ylabel(\"BLEU score\")\n",
    "plt.savefig(\"plots/bleu_boxplot.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T04:56:02.809747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-16T04:56:02.809783Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
