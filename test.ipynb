{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.mps\n",
    "\n",
    "from decoder import AttnDecoderRNN\n",
    "from encoder import EncoderRNN\n",
    "from train import *\n",
    "from evaluate import inference\n",
    "from dataloader import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:31:00.958219600Z",
     "start_time": "2023-06-14T20:30:58.612289Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "models_dir = \"models\"\n",
    "model_name = \"100p_tfr_1e-4_lr_320_hidden_6_layers_40p_dropout\"\n",
    "plots_dir = \"plots\"\n",
    "\n",
    "max_length = 20\n",
    "teacher_forcing_ratio = 1\n",
    "lr = 1e-4\n",
    "hidden_size = 512\n",
    "n_encoder_layers = 4\n",
    "n_decoder_layers = 4\n",
    "dropout = 0.1\n",
    "\n",
    "# input_lang, output_lang, pairs = prepare_data('data/train.en', 'data/train.de', n_samples, start_from_sample)\n",
    "# print(f'number of pairs: {len(pairs)}')\n",
    "\n",
    "# encoder = EncoderRNN(28996, hidden_size, num_layers=n_encoder_layers, dropout_p=dropout).to(device)\n",
    "# attn_decoder = AttnDecoderRNN(hidden_size, 30000, num_layers=n_decoder_layers,\n",
    "#                               dropout_p=dropout, max_length=max_length).to(device)\n",
    "\n",
    "input_lang = Lang(\"en\")\n",
    "output_lang = Lang(\"de\")\n",
    "\n",
    "encoder = torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device)\n",
    "# .load_state_dict(torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device))\n",
    "attn_decoder = torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device)\n",
    "# .load_state_dict(torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:34:20.055419400Z",
     "start_time": "2023-06-14T20:34:19.290413200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "decoded_words, _ = inference(encoder, attn_decoder, \"I am going with you\", input_lang, output_lang, max_length=max_length, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:34:20.247011700Z",
     "start_time": "2023-06-14T20:34:20.056423300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "' Die ist Sie , , . . . <EOS>'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(decoded_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:34:20.280661800Z",
     "start_time": "2023-06-14T20:34:20.266538500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Normalizing...\n",
      "Read 100000 sentence pairs\n",
      "Trimmed to 18381 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "en 50002\n",
      "de 50002\n"
     ]
    }
   ],
   "source": [
    "from dataloader import *\n",
    "n_samples = 100000\n",
    "start_from_sample = 0\n",
    "input_lang, output_lang, pairs = prepare_data('data/train.en', 'data/train.de', n_samples, start_from_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T18:46:26.750439100Z",
     "start_time": "2023-06-11T18:46:17.144256900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def find_all_unk_pairs(pairs):\n",
    "    n_unks = 0\n",
    "    for pair in pairs:\n",
    "        is_unk = False\n",
    "        for word in pair[0].split(' '):\n",
    "            if word not in input_lang.word2index:\n",
    "                is_unk = True\n",
    "                break\n",
    "        if not is_unk:\n",
    "            for word in pair[1].split(' '):\n",
    "                if word not in output_lang.word2index:\n",
    "                    is_unk = True\n",
    "                    break\n",
    "        if is_unk:\n",
    "            n_unks += 1\n",
    "\n",
    "    return n_unks\n",
    "\n",
    "\n",
    "def find_all_unks(pairs):\n",
    "    n_unks = 0\n",
    "    for pair in pairs:\n",
    "        for word in pair[0].split(' '):\n",
    "            if word not in input_lang.word2index:\n",
    "                n_unks += 1\n",
    "        for word in pair[1].split(' '):\n",
    "            if word not in output_lang.word2index:\n",
    "                n_unks += 1\n",
    "\n",
    "    return n_unks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T18:50:19.769023Z",
     "start_time": "2023-06-11T18:50:19.753329600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs: 18381\n",
      "number of words: 397916\n",
      "number of unk pairs: 17609\n",
      "number of unk words: 66606\n"
     ]
    }
   ],
   "source": [
    "print(f'number of pairs: {len(pairs)}')\n",
    "print(f'number of words: {sum([len(pair[0].split(\" \")) + len(pair[1].split(\" \")) for pair in pairs])}')\n",
    "print(f'number of unk pairs: {find_all_unk_pairs(pairs)}')\n",
    "print(f'number of unk words: {find_all_unks(pairs)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T18:50:28.168103200Z",
     "start_time": "2023-06-11T18:50:28.044307300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.tensor([1, 2, 3])\n",
    "x = t[torch.randperm(t.size(0))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T19:37:09.109237300Z",
     "start_time": "2023-06-11T19:37:09.103321900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1, 2, 3]), tensor([2, 1, 3]))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T19:37:09.262474200Z",
     "start_time": "2023-06-11T19:37:09.256993400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
