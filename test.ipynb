{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.mps\n",
    "\n",
    "from decoder import AttnDecoderRNN\n",
    "from encoder import EncoderRNN\n",
    "from train import *\n",
    "from evaluate import evaluate\n",
    "from dataloader import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T15:37:52.863433100Z",
     "start_time": "2023-06-11T15:37:50.800877600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Normalizing...\n",
      "Read 10 sentence pairs\n",
      "Trimmed to 6 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "en 50002\n",
      "de 50002\n",
      "number of pairs: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dir = \"models\"\n",
    "model_name = \"4_layers_512_hidden_1e-4_lr\"\n",
    "plots_dir = \"plots\"\n",
    "\n",
    "teacher_forcing_ratio = 1\n",
    "lr = 1e-4\n",
    "hidden_size = 512\n",
    "n_encoder_layers = 4\n",
    "n_decoder_layers = 4\n",
    "dropout = 0.1\n",
    "\n",
    "start_from_sample = 0\n",
    "n_samples = 10\n",
    "\n",
    "print_every = 100\n",
    "plot_every = 1000\n",
    "save_every = 1000\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('data/train.en', 'data/train.de', n_samples, start_from_sample)\n",
    "print(f'number of pairs: {len(pairs)}')\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, num_layers=n_encoder_layers).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, num_layers=n_decoder_layers, dropout_p=dropout,\n",
    "                              max_length=MAX_LENGTH).to(device)\n",
    "\n",
    "encoder.load_state_dict(torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device))\n",
    "attn_decoder.load_state_dict(torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T15:39:43.397214400Z",
     "start_time": "2023-06-11T15:39:38.735309300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "decoded_words, _ = evaluate(encoder, attn_decoder, \"you and me\", input_lang, output_lang, max_length=MAX_LENGTH, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T15:40:15.161036400Z",
     "start_time": "2023-06-11T15:40:15.054729900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'<unk> <unk> <unk> <unk> <unk> <EOS>'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(decoded_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T15:40:15.383909900Z",
     "start_time": "2023-06-11T15:40:15.370903400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Normalizing...\n",
      "Read 100000 sentence pairs\n",
      "Trimmed to 18381 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "en 50002\n",
      "de 50002\n"
     ]
    }
   ],
   "source": [
    "from dataloader import *\n",
    "n_samples = 100000\n",
    "start_from_sample = 0\n",
    "input_lang, output_lang, pairs = prepare_data('data/train.en', 'data/train.de', n_samples, start_from_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T18:46:26.750439100Z",
     "start_time": "2023-06-11T18:46:17.144256900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def find_all_unk_pairs(pairs):\n",
    "    n_unks = 0\n",
    "    for pair in pairs:\n",
    "        is_unk = False\n",
    "        for word in pair[0].split(' '):\n",
    "            if word not in input_lang.word2index:\n",
    "                is_unk = True\n",
    "                break\n",
    "        if not is_unk:\n",
    "            for word in pair[1].split(' '):\n",
    "                if word not in output_lang.word2index:\n",
    "                    is_unk = True\n",
    "                    break\n",
    "        if is_unk:\n",
    "            n_unks += 1\n",
    "\n",
    "    return n_unks\n",
    "\n",
    "\n",
    "def find_all_unks(pairs):\n",
    "    n_unks = 0\n",
    "    for pair in pairs:\n",
    "        for word in pair[0].split(' '):\n",
    "            if word not in input_lang.word2index:\n",
    "                n_unks += 1\n",
    "        for word in pair[1].split(' '):\n",
    "            if word not in output_lang.word2index:\n",
    "                n_unks += 1\n",
    "\n",
    "    return n_unks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T18:50:19.769023Z",
     "start_time": "2023-06-11T18:50:19.753329600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs: 18381\n",
      "number of words: 397916\n",
      "number of unk pairs: 17609\n",
      "number of unk words: 66606\n"
     ]
    }
   ],
   "source": [
    "print(f'number of pairs: {len(pairs)}')\n",
    "print(f'number of words: {sum([len(pair[0].split(\" \")) + len(pair[1].split(\" \")) for pair in pairs])}')\n",
    "print(f'number of unk pairs: {find_all_unk_pairs(pairs)}')\n",
    "print(f'number of unk words: {find_all_unks(pairs)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T18:50:28.168103200Z",
     "start_time": "2023-06-11T18:50:28.044307300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.tensor([1, 2, 3])\n",
    "x = t[torch.randperm(t.size(0))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T19:37:09.109237300Z",
     "start_time": "2023-06-11T19:37:09.103321900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1, 2, 3]), tensor([2, 1, 3]))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T19:37:09.262474200Z",
     "start_time": "2023-06-11T19:37:09.256993400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
