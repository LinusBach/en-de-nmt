{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:00:14.660554Z",
     "start_time": "2023-06-16T15:00:11.444487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.mps\n",
    "\n",
    "from decoder import AttnDecoderRNN\n",
    "from encoder import EncoderRNN\n",
    "from evaluation_functions import inference, evaluate_bertscore\n",
    "from dataloader import Lang, prepare_data\n",
    "from io import open\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 346 sentence pairs\n",
      "Train sequences: 1\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 234.42it/s]\n"
     ]
    }
   ],
   "source": [
    "loaded_data = 1000\n",
    "validation_size = 300\n",
    "train_size = 1\n",
    "max_length = 30  # max length of 30 retains around 1/3 of the data; 20 => 1/8\n",
    "\n",
    "input_lang, output_lang, english_sequences, german_sequences, validation_english, validation_german = \\\n",
    "    prepare_data('data/train.en', 'data/train.de', max_length, train_size, validation_size,\n",
    "                 loaded_data=loaded_data, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:00:17.348545Z",
     "start_time": "2023-06-16T15:00:14.662109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "models_dir = \"models_gru\"\n",
    "model_name = \"5e-5_lr_1_layer_100_hidden_2\"\n",
    "encoder = torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device)\n",
    "decoder = torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:00:17.411094Z",
     "start_time": "2023-06-16T15:00:17.350004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.291608810424805\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.389435350894928,\n 0.356946736574173,\n 0.36033084988594055,\n 0.3768613338470459,\n 0.3851816654205322,\n 0.3716244399547577,\n 0.36954617500305176,\n 0.37553325295448303,\n 0.36251100897789,\n 0.3711259365081787,\n 0.4110725224018097,\n 0.4324071705341339,\n 0.38086700439453125,\n 0.3541617691516876,\n 0.41357097029685974,\n 0.3884272575378418,\n 0.380095899105072,\n 0.39330539107322693,\n 0.34811633825302124,\n 0.39452847838401794,\n 0.3903738856315613,\n 0.4500541388988495,\n 0.4144149720668793,\n 0.36120980978012085,\n 0.39022788405418396,\n 0.3812312185764313,\n 0.3748236298561096,\n 0.40792056918144226,\n 0.4093226492404938,\n 0.37486594915390015,\n 0.3817298710346222,\n 0.4157201051712036,\n 0.3853645324707031,\n 0.3992069959640503,\n 0.3734957277774811,\n 0.3587798774242401,\n 0.3531423807144165,\n 0.3806183934211731,\n 0.39056965708732605,\n 0.3757345378398895,\n 0.40238258242607117,\n 0.3632217049598694,\n 0.38252297043800354,\n 0.3610265552997589,\n 0.4040934145450592,\n 0.4743151068687439,\n 0.4495171904563904,\n 0.3830730617046356,\n 0.4118137061595917,\n 0.40458840131759644,\n 0.3798398971557617,\n 0.379908949136734,\n 0.40886780619621277,\n 0.3936414122581482,\n 0.3934197425842285,\n 0.39398840069770813,\n 0.431056410074234,\n 0.3820053040981293,\n 0.3878817856311798,\n 0.44879066944122314,\n 0.4007512032985687,\n 0.38050344586372375,\n 0.36594751477241516,\n 0.401788592338562,\n 0.4124763607978821,\n 0.34891852736473083,\n 0.4206158518791199,\n 0.36653536558151245,\n 0.4094167947769165,\n 0.39247822761535645,\n 0.39372870326042175,\n 0.39813822507858276,\n 0.4528474807739258,\n 0.4607587158679962,\n 0.38343116641044617,\n 0.3994767665863037,\n 0.4183647036552429,\n 0.3200221657752991,\n 0.3642868101596832,\n 0.5031904578208923,\n 0.3856770396232605,\n 0.39018192887306213,\n 0.37269169092178345,\n 0.35289686918258667,\n 0.40750616788864136,\n 0.38442665338516235,\n 0.3701798915863037,\n 0.3695749342441559,\n 0.4154462516307831,\n 0.3513062298297882,\n 0.39779552817344666,\n 0.3741283714771271,\n 0.36981523036956787,\n 0.3716146647930145,\n 0.3881816565990448,\n 0.37869012355804443,\n 0.45344555377960205,\n 0.39453715085983276,\n 0.41964298486709595,\n 0.3724154829978943,\n 0.37459200620651245,\n 0.38668185472488403,\n 0.39326152205467224,\n 0.39956748485565186,\n 0.429810494184494,\n 0.4032915532588959,\n 0.39914828538894653,\n 0.40702053904533386,\n 0.39370056986808777,\n 0.3661641776561737,\n 0.42087680101394653,\n 0.3894234299659729,\n 0.4171470105648041,\n 0.3956761062145233,\n 0.39400580525398254,\n 0.3415798842906952,\n 0.4256952404975891,\n 0.4453645646572113,\n 0.39559799432754517,\n 0.3821115493774414,\n 0.374704509973526,\n 0.3733055293560028,\n 0.3921988904476166,\n 0.37188196182250977,\n 0.4296775162220001,\n 0.41759538650512695,\n 0.36748072504997253,\n 0.45522060990333557,\n 0.38311612606048584,\n 0.4600050747394562,\n 0.35655033588409424,\n 0.46211305260658264,\n 0.34995776414871216,\n 0.4215598404407501,\n 0.3791273236274719,\n 0.3470907509326935,\n 0.40252694487571716,\n 0.3426108658313751,\n 0.36042460799217224,\n 0.36981359124183655,\n 0.3891550600528717,\n 0.40627536177635193,\n 0.37352055311203003,\n 0.38205939531326294,\n 0.40347182750701904,\n 0.44346359372138977,\n 0.3860490322113037,\n 0.4134780764579773,\n 0.39038175344467163,\n 0.34691768884658813,\n 0.389435350894928,\n 0.4539470374584198,\n 0.37975525856018066,\n 0.39753928780555725,\n 0.3792271912097931,\n 0.3527121841907501,\n 0.3894193470478058,\n 0.36625587940216064,\n 0.36677759885787964,\n 0.37622204422950745,\n 0.3487689197063446,\n 0.38839706778526306,\n 0.47540023922920227,\n 0.38526231050491333,\n 0.3789799213409424,\n 0.38877370953559875,\n 0.36035144329071045,\n 0.4234643876552582,\n 0.3885357677936554,\n 0.3833591639995575,\n 0.4113915264606476,\n 0.39561566710472107,\n 0.3904837369918823,\n 0.39013200998306274,\n 0.402931272983551,\n 0.40020251274108887,\n 0.38224491477012634,\n 0.40237191319465637,\n 0.366717666387558,\n 0.3634931743144989,\n 0.39693790674209595,\n 0.4064820408821106,\n 0.4141787588596344,\n 0.36914944648742676,\n 0.40767234563827515,\n 0.4591389298439026,\n 0.38670822978019714,\n 0.3435562252998352,\n 0.36719226837158203,\n 0.43299347162246704,\n 0.37578338384628296,\n 0.4201395809650421,\n 0.39392372965812683,\n 0.3789849579334259,\n 0.39068329334259033,\n 0.43239983916282654,\n 0.351994127035141,\n 0.37532344460487366,\n 0.4070209562778473,\n 0.3724735379219055,\n 0.3708597421646118,\n 0.4039306938648224,\n 0.3938417136669159,\n 0.36720776557922363,\n 0.36936429142951965,\n 0.38941511511802673,\n 0.4739474654197693,\n 0.41076770424842834,\n 0.3475591838359833,\n 0.44563159346580505,\n 0.39422282576560974,\n 0.4094436466693878,\n 0.3701736629009247,\n 0.392393559217453,\n 0.4023905396461487,\n 0.41402631998062134,\n 0.3944285213947296,\n 0.3909446895122528,\n 0.36103925108909607,\n 0.40019696950912476,\n 0.38615575432777405,\n 0.3951907753944397,\n 0.4110275208950043,\n 0.3975222706794739,\n 0.3773553669452667,\n 0.36714527010917664,\n 0.36255860328674316,\n 0.4111175537109375,\n 0.39118751883506775,\n 0.40983912348747253,\n 0.4334454834461212,\n 0.35288485884666443,\n 0.3740538954734802,\n 0.3695547580718994,\n 0.3735167682170868,\n 0.362009733915329,\n 0.40242093801498413,\n 0.3881698548793793,\n 0.37386390566825867,\n 0.37534040212631226,\n 0.45561885833740234,\n 0.36880752444267273,\n 0.38918739557266235,\n 0.35659611225128174,\n 0.369179904460907,\n 0.39841046929359436,\n 0.40011149644851685,\n 0.4155893623828888,\n 0.4015013575553894,\n 0.369267076253891,\n 0.45127639174461365,\n 0.4016984701156616,\n 0.3551473915576935,\n 0.35873162746429443,\n 0.36668869853019714,\n 0.39519602060317993,\n 0.41527581214904785,\n 0.36168521642684937,\n 0.3806416094303131,\n 0.38646945357322693,\n 0.3893302381038666,\n 0.3567555844783783,\n 0.3635840117931366,\n 0.39421695470809937,\n 0.3541080951690674,\n 0.3705686628818512,\n 0.45520758628845215,\n 0.38161909580230713,\n 0.35455137491226196,\n 0.4017336368560791,\n 0.3547421991825104,\n 0.39756277203559875,\n 0.4332094192504883,\n 0.3662368655204773,\n 0.42236262559890747,\n 0.36227715015411377,\n 0.3816967308521271,\n 0.37987908720970154,\n 0.41332411766052246,\n 0.43014103174209595,\n 0.44511136412620544,\n 0.35894402861595154,\n 0.42467525601387024,\n 0.42580506205558777,\n 0.3805040121078491,\n 0.346802681684494,\n 0.37880364060401917,\n 0.40792787075042725,\n 0.4560964107513428,\n 0.3769906461238861,\n 0.39451900124549866,\n 0.36649608612060547,\n 0.38735175132751465,\n 0.3682993948459625,\n 0.406868040561676,\n 0.40567511320114136,\n 0.3902136981487274,\n 0.38995078206062317,\n 0.4361621141433716,\n 0.36121225357055664]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_score = evaluate_bertscore(encoder, decoder, validation_english, validation_german, input_lang, output_lang, 30, \"facebook/bart-large-mnli\", device)\n",
    "bert_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:02:34.688084Z",
     "start_time": "2023-06-16T15:01:55.605581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.191924810409546\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4209511876106262,\n 0.422923743724823,\n 0.4632260799407959,\n 0.34269681572914124,\n 0.4507923126220703,\n 0.3699100911617279,\n 0.39163830876350403,\n 0.4027002155780792,\n 0.35307982563972473,\n 0.4254568815231323,\n 0.4391911029815674,\n 0.4642578959465027,\n 0.38709384202957153,\n 0.4413072466850281,\n 0.42415034770965576,\n 0.38990527391433716,\n 0.44043976068496704,\n 0.4513382017612457,\n 0.45362773537635803,\n 0.4717690348625183,\n 0.43379971385002136,\n 0.4346602261066437,\n 0.44217076897621155,\n 0.39455941319465637,\n 0.44540920853614807,\n 0.4708751440048218,\n 0.44468367099761963,\n 0.39874961972236633,\n 0.3694831430912018,\n 0.3689633011817932,\n 0.46965292096138,\n 0.5043194890022278,\n 0.46716374158859253,\n 0.4638514518737793,\n 0.4258023798465729,\n 0.41160547733306885,\n 0.3611133098602295,\n 0.44868266582489014,\n 0.41786783933639526,\n 0.4218587577342987,\n 0.45299363136291504,\n 0.4682697057723999,\n 0.3771536350250244,\n 0.3770250380039215,\n 0.4611715078353882,\n 0.4504491984844208,\n 0.4633494019508362,\n 0.41343382000923157,\n 0.45984452962875366,\n 0.39904308319091797,\n 0.46773606538772583,\n 0.4561489522457123,\n 0.3938708007335663,\n 0.4596647024154663,\n 0.4314369559288025,\n 0.41954073309898376,\n 0.38755616545677185,\n 0.4463202655315399,\n 0.3829081058502197,\n 0.4703797996044159,\n 0.4165358245372772,\n 0.42192545533180237,\n 0.4444485604763031,\n 0.4050137400627136,\n 0.48609602451324463,\n 0.41528764367103577,\n 0.4122893810272217,\n 0.4271184206008911,\n 0.47779273986816406,\n 0.34409379959106445,\n 0.3785935938358307,\n 0.3892436623573303,\n 0.4456024765968323,\n 0.47646328806877136,\n 0.4097818434238434,\n 0.44221073389053345,\n 0.4605143666267395,\n 0.36028480529785156,\n 0.39492952823638916,\n 0.494973748922348,\n 0.4484647214412689,\n 0.4377202093601227,\n 0.4222423732280731,\n 0.3969357907772064,\n 0.4520871043205261,\n 0.36212730407714844,\n 0.40853795409202576,\n 0.4126197397708893,\n 0.41952359676361084,\n 0.33321911096572876,\n 0.44847241044044495,\n 0.38769131898880005,\n 0.3701164424419403,\n 0.3920947313308716,\n 0.4516042470932007,\n 0.4461653232574463,\n 0.502142608165741,\n 0.3631788492202759,\n 0.48079338669776917,\n 0.4203033149242401,\n 0.44200995564460754,\n 0.47571760416030884,\n 0.4539863169193268,\n 0.4146692156791687,\n 0.4505294859409332,\n 0.4485652446746826,\n 0.3874935805797577,\n 0.4540044069290161,\n 0.4109342098236084,\n 0.40792590379714966,\n 0.4508642554283142,\n 0.39762333035469055,\n 0.45031997561454773,\n 0.4641495943069458,\n 0.4503497779369354,\n 0.3664434254169464,\n 0.4865587651729584,\n 0.4518309235572815,\n 0.42514824867248535,\n 0.36985957622528076,\n 0.49101537466049194,\n 0.45047155022621155,\n 0.45644575357437134,\n 0.37374377250671387,\n 0.438661128282547,\n 0.4761458933353424,\n 0.4601115584373474,\n 0.4726068675518036,\n 0.4035876393318176,\n 0.46839699149131775,\n 0.4159703850746155,\n 0.5256651639938354,\n 0.39313241839408875,\n 0.4648703336715698,\n 0.3599131107330322,\n 0.3537592589855194,\n 0.4368549585342407,\n 0.3711884021759033,\n 0.392799973487854,\n 0.33204934000968933,\n 0.4523927867412567,\n 0.3786278963088989,\n 0.41950711607933044,\n 0.4518125057220459,\n 0.40942227840423584,\n 0.4654485583305359,\n 0.41468024253845215,\n 0.44466954469680786,\n 0.39675673842430115,\n 0.38444820046424866,\n 0.4209511876106262,\n 0.40552711486816406,\n 0.39113515615463257,\n 0.4230901896953583,\n 0.4294681251049042,\n 0.4020422697067261,\n 0.4666495621204376,\n 0.35176151990890503,\n 0.4146643579006195,\n 0.3665948510169983,\n 0.43160971999168396,\n 0.4298897087574005,\n 0.5144835710525513,\n 0.40409621596336365,\n 0.41285616159439087,\n 0.428907573223114,\n 0.4515291154384613,\n 0.4628582000732422,\n 0.4697985351085663,\n 0.3987919092178345,\n 0.39895501732826233,\n 0.4172913432121277,\n 0.38726183772087097,\n 0.47608622908592224,\n 0.4767460227012634,\n 0.35531073808670044,\n 0.450992226600647,\n 0.46469512581825256,\n 0.432860791683197,\n 0.38589149713516235,\n 0.3859609067440033,\n 0.4561273455619812,\n 0.5022052526473999,\n 0.4197046756744385,\n 0.4701392948627472,\n 0.4876675307750702,\n 0.4562608301639557,\n 0.3860570788383484,\n 0.415546178817749,\n 0.415617972612381,\n 0.43002572655677795,\n 0.48489683866500854,\n 0.41101136803627014,\n 0.3811054229736328,\n 0.44704294204711914,\n 0.44304972887039185,\n 0.3816843628883362,\n 0.4130418598651886,\n 0.42360562086105347,\n 0.38109254837036133,\n 0.4405999481678009,\n 0.4735661745071411,\n 0.32119837403297424,\n 0.35986626148223877,\n 0.4686780571937561,\n 0.48319000005722046,\n 0.503470242023468,\n 0.4655471742153168,\n 0.38905468583106995,\n 0.4843505322933197,\n 0.4868321716785431,\n 0.4208446443080902,\n 0.41245409846305847,\n 0.37776070833206177,\n 0.4198238253593445,\n 0.4064198136329651,\n 0.38794955611228943,\n 0.4421338140964508,\n 0.4222720265388489,\n 0.4638112783432007,\n 0.3488410711288452,\n 0.43914616107940674,\n 0.4426857829093933,\n 0.3900916576385498,\n 0.46193358302116394,\n 0.43040046095848083,\n 0.4538131654262543,\n 0.43595683574676514,\n 0.4733223021030426,\n 0.5001949667930603,\n 0.48436054587364197,\n 0.43315425515174866,\n 0.4118276536464691,\n 0.38945698738098145,\n 0.42472556233406067,\n 0.3757246732711792,\n 0.37243127822875977,\n 0.44920092821121216,\n 0.3819398581981659,\n 0.3815375566482544,\n 0.4434414207935333,\n 0.4138391315937042,\n 0.4760438799858093,\n 0.42125988006591797,\n 0.37256449460983276,\n 0.5065752863883972,\n 0.36043962836265564,\n 0.39395755529403687,\n 0.396456778049469,\n 0.35909438133239746,\n 0.46565690636634827,\n 0.41983601450920105,\n 0.4215855002403259,\n 0.3331564664840698,\n 0.3705464005470276,\n 0.44270533323287964,\n 0.48071208596229553,\n 0.3388345241546631,\n 0.44279932975769043,\n 0.43205705285072327,\n 0.44013094902038574,\n 0.39959174394607544,\n 0.4353523254394531,\n 0.3678915202617645,\n 0.380349338054657,\n 0.3891156017780304,\n 0.47791019082069397,\n 0.3859323561191559,\n 0.3687357008457184,\n 0.43159791827201843,\n 0.386892706155777,\n 0.4341885447502136,\n 0.43469879031181335,\n 0.3948843479156494,\n 0.41348132491111755,\n 0.40771758556365967,\n 0.3465614914894104,\n 0.35217127203941345,\n 0.4492824375629425,\n 0.4132261574268341,\n 0.48952600359916687,\n 0.4243413209915161,\n 0.47964394092559814,\n 0.49444758892059326,\n 0.3985884487628937,\n 0.37502601742744446,\n 0.4356413185596466,\n 0.47314733266830444,\n 0.4492369592189789,\n 0.4158083200454712,\n 0.438096821308136,\n 0.4017364978790283,\n 0.45206835865974426,\n 0.46616053581237793,\n 0.406125545501709,\n 0.4730418920516968,\n 0.38389334082603455,\n 0.4096699655056,\n 0.4718775451183319,\n 0.35063931345939636]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_score = evaluate_bertscore(encoder, decoder, validation_english, validation_german, input_lang, output_lang, 30, \"microsoft/deberta-xlarge-mnli\", device)\n",
    "bert_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:03:22.467109Z",
     "start_time": "2023-06-16T15:02:34.689700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "300"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_english)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:03:22.481114Z",
     "start_time": "2023-06-16T15:03:22.477731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from time import time\n",
    "bertscore = load(\"bertscore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:51:33.753536Z",
     "start_time": "2023-06-16T14:51:33.006491Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07848000526428223\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "predictions = [\"Das Hotel ist zentral\", \"general kenobi\"][:1]\n",
    "references = [\"Das Hotel ist zentral\", \"hello there\"][:1]\n",
    "bertscore.compute(predictions=predictions, references=references, model_type=\"facebook/bart-large-mnli\", lang=\"de\", device=\"cpu\")\n",
    "print(time() - t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:55:33.715089Z",
     "start_time": "2023-06-16T14:55:33.636241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0687861442565918\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "predictions = [\"Das Hotel ist zentral\", \"general kenobi\"][:1]\n",
    "references = [\"Das Hotel ist zentral\", \"hello there\"][:1]\n",
    "bertscore.compute(predictions=predictions, references=references, model_type=\"facebook/bart-large-mnli\", lang=\"de\", device=\"mps\")\n",
    "print(time() - t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T14:55:34.425088Z",
     "start_time": "2023-06-16T14:55:34.356154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
