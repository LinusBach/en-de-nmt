{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.backends.mps\n",
    "\n",
    "from decoder import AttnDecoderRNN\n",
    "from encoder import EncoderRNN\n",
    "from evaluate import evaluate_losses, inference, evaluate_bleu, evaluate_loss\n",
    "from dataloader import Lang\n",
    "from io import open\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:23:23.326811900Z",
     "start_time": "2023-06-20T18:23:20.913000200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation size: 2534\n"
     ]
    }
   ],
   "source": [
    "initial_validation_size = 20000\n",
    "max_length = 20\n",
    "input_lang = Lang(\"en\")\n",
    "output_lang = Lang(\"de\")\n",
    "\n",
    "validation_english = open(\"data/train.en\", encoding='utf-8').readlines()[:initial_validation_size]\n",
    "validation_german = open(\"data/train.de\", encoding='utf-8').readlines()[:initial_validation_size]\n",
    "zipped = list(zip(validation_english, validation_german))\n",
    "validation_english = [english for english, german in zipped\n",
    "                      if len(input_lang.tokenize_without_truncation(english)) < max_length\n",
    "                      and len(output_lang.tokenize_without_truncation(german)) < max_length]\n",
    "validation_german = [german for english, german in zipped\n",
    "                     if len(input_lang.tokenize_without_truncation(english)) < max_length\n",
    "                     and len(output_lang.tokenize_without_truncation(german)) < max_length]\n",
    "# validation_german = [[output_lang.decode(token) for token in output_lang.tokenize(sentence)][1:-1] for sentence in validation_german]\n",
    "print(f\"validation size: {len(validation_english)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:23:32.513568200Z",
     "start_time": "2023-06-20T18:23:23.326811900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "losses_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:23:32.560492400Z",
     "start_time": "2023-06-20T18:23:32.513568200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_names = [\n",
    "\"1e-3_lr_256_hidden_4_layers_20p_dropout\",\n",
    "\"1e-4_lr_320_hidden_4_layers_10p_dropout\",\n",
    "\"3e-4_lr_320_hidden_4_layers_20p_dropout\",\n",
    "\"3e-5_lr_320_hidden_5_layers_30p_dropout\",\n",
    "\"50p_tfr_1e-4_lr_320_hidden_4_layers_10p_dropout\",\n",
    "\"80p_tfr_3e-4_lr_320_hidden_5_layers_30p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_320_hidden_6_layers_40p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_512_hidden_8_layers_50p_dropout\",\n",
    "\"100p_tfr_2e-4_lr_400_hidden_8_layers_60p_dropout\",\n",
    "\"100p_tfr_5e-5_lr_512_hidden_8_layers_60p_dropout_1e-4_weight_decay\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:23:32.560492400Z",
     "start_time": "2023-06-20T18:23:32.529193300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "lstm_model_names = [\n",
    "\"80p_tfr_3e-4_lr_320_hidden_5_layers_30p_dropout\",\n",
    "\"50p_tfr_1e-4_lr_320_hidden_4_layers_10p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_320_hidden_6_layers_40p_dropout\",\n",
    "\"100p_tfr_1e-4_lr_512_hidden_8_layers_50p_dropout\",\n",
    "\"100p_tfr_2e-4_lr_400_hidden_8_layers_60p_dropout\",\n",
    "\"100p_tfr_5e-5_lr_512_hidden_8_layers_60p_dropout_1e-4_weight_decay\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:23:32.560492400Z",
     "start_time": "2023-06-20T18:23:32.560492400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 80p_tfr_3e-4_lr_320_hidden_5_layers_30p_dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2534 [00:00<?, ?it/s]C:\\Users\\Lennart\\.conda\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:968.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "100%|██████████| 2534/2534 [01:22<00:00, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.043328820083117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# losses_list = []\n",
    "for i in range(1):\n",
    "    models_dir = \"models_lstm\"\n",
    "    model_name = lstm_model_names[i]\n",
    "\n",
    "    encoder = torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device)\n",
    "    attn_decoder = torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device)\n",
    "    # prev_loss_history = np.load(os.path.join(plots_dir, model_name + \"_full_history.npy\")).tolist()\n",
    "    # prev_plot_history = np.load(os.path.join(plots_dir, model_name + \"_plot_history.npy\")).tolist()\n",
    "\n",
    "    print(f\"Evaluating model {model_name}\")\n",
    "    loss, losses = evaluate_losses(encoder, attn_decoder, validation_english, validation_german, input_lang, output_lang, max_length, device)\n",
    "    losses_list.append((loss, losses))\n",
    "    print(f\"Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:24:54.826001500Z",
     "start_time": "2023-06-20T18:23:32.560492400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:24:54.872876500Z",
     "start_time": "2023-06-20T18:24:54.826001500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 80p_tfr_3e-4_lr_320_hidden_5_layers_30p_dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2534/2534 [01:33<00:00, 27.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.015802574814471573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chencherry = SmoothingFunction()\n",
    "all_bleu_scores = []\n",
    "\n",
    "for i in range(1):\n",
    "    models_dir = \"models_lstm\"\n",
    "    model_name = lstm_model_names[i]\n",
    "\n",
    "    encoder = torch.load(os.path.join(models_dir, model_name, \"encoder.pt\"), map_location=device)\n",
    "    decoder = torch.load(os.path.join(models_dir, model_name, \"decoder.pt\"), map_location=device)\n",
    "    # prev_loss_history = np.load(os.path.join(plots_dir, model_name + \"_full_history.npy\")).tolist()\n",
    "    # prev_plot_history = np.load(os.path.join(plots_dir, model_name + \"_plot_history.npy\")).tolist()\n",
    "\n",
    "    print(f\"Evaluating model {model_name}\")\n",
    "    bleu_scores = []\n",
    "    for j in tqdm(range(len(validation_english))):\n",
    "        prediction, _ = inference(encoder, decoder, validation_english[j], input_lang, output_lang, max_length, device)\n",
    "        bleu_score = sentence_bleu(validation_german[j], prediction[1:-1], (0.25, 0.25, 0.25, 0.25), smoothing_function=chencherry.method1)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    # print(f\"Prediction: {prediction[1:-1]}\")\n",
    "    print(f\"BLEU score: {np.mean(bleu_scores)}\")\n",
    "    all_bleu_scores.append(bleu_scores)\n",
    "    # loss, losses = evaluate_losses(encoder, attn_decoder, validation_english, validation_german, input_lang, output_lang, max_length, device)\n",
    "    # losses_list.append((loss, losses))\n",
    "    # print(f\"Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T18:28:27.235103200Z",
     "start_time": "2023-06-20T18:26:53.845843400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "np.save(\"evaluation_loss.npy\", losses_list[0][1])\n",
    "np.save(\"evaluation_bleu.npy\", np.array(all_bleu_scores[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T19:51:06.552551Z",
     "start_time": "2023-06-20T19:51:06.521107500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "losses = np.load(\"evaluation_loss.npy\", allow_pickle=True)\n",
    "bleu_scores = np.load(\"evaluation_bleu.npy\", allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T19:51:32.882583900Z",
     "start_time": "2023-06-20T19:51:32.866784600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2534,)\n",
      "(2534,)\n"
     ]
    }
   ],
   "source": [
    "print(losses.shape)\n",
    "print(bleu_scores.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T19:51:43.141106Z",
     "start_time": "2023-06-20T19:51:43.125462400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_of_interest = [4, 5, 8, 9]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.boxplot([losses_list[i][1] for i in models_of_interest])\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.title(\"Validation loss for GRU models\")\n",
    "plt.ylim(0, 12)\n",
    "plt.savefig(\"plots/losses_boxplot.png\", bbox_inches='tight', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.boxplot([all_bleu_scores[i] for i in models_of_interest])\n",
    "plt.ylabel(\"BLEU score\")\n",
    "plt.title(\"BLEU score for GRU models\")\n",
    "# set axis limits\n",
    "plt.ylim(0.0, 0.12)\n",
    "plt.savefig(\"plots/bleu_boxplot.png\", bbox_inches='tight', dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
